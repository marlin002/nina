# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
User-agent: *
Allow: /
Allow: /scrapes/about
Allow: /scrapes/all
Allow: /scrapes/api-info
# Block searches
Disallow: /search*
Disallow: /scrapes/search*
